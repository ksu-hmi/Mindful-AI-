{"cells":[{"cell_type":"markdown","metadata":{"id":"6GUbwjVfCunz"},"source":["# Word2Vec\n","This notebook aims to train word embeddings using the Word2Vec model."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21290,"status":"ok","timestamp":1636736679038,"user":{"displayName":"Lim Zi Hui","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPiWA2f_lOpcH4ednxJY0WKKtdAd8lFhippOJxag=s64","userId":"01552686661266028096"},"user_tz":-480},"id":"n_q3Y1Zc0s7F","outputId":"a90046a2-350d-486f-c1f8-6f15b5344c17"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m, force_remount\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IgRdNSJElABB"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","\n","from sklearn.model_selection import train_test_split\n","from gensim.models import Word2Vec\n","from time import time\n","from collections import Counter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbqFqlVk26SP"},"outputs":[],"source":["SEED = 4222\n","EPOCHS = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1636736684681,"user":{"displayName":"Lim Zi Hui","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPiWA2f_lOpcH4ednxJY0WKKtdAd8lFhippOJxag=s64","userId":"01552686661266028096"},"user_tz":-480},"id":"_ccDHJwJ7xqa","outputId":"2a0e1c05-e618-4e91-835a-c0c8f102f2a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Directory changed\n"]}],"source":["# Change to your own directory\n","try: \n","    os.chdir(\"/content/drive/MyDrive/MindfulAIProject\")\n","    print(\"Directory changed\")\n","except OSError:\n","    print(\"Error: Can't change the Current Working Directory\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":4141,"status":"ok","timestamp":1636736690108,"user":{"displayName":"Lim Zi Hui","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPiWA2f_lOpcH4ednxJY0WKKtdAd8lFhippOJxag=s64","userId":"01552686661266028096"},"user_tz":-480},"id":"aJWPJjlKk194","outputId":"c21dea5c-4ed3-4645-e574-3e61215a9c83"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>sex wife threaten suicide recently leave wife ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>weird not affect compliment come know real lif...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>finally hear bad year swear fucking god annoying</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>need help just help cry hard</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>end tonight not anymore quit</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>174431</th>\n","      <td>0</td>\n","      <td>today go sled friend not like of pretty big mi...</td>\n","    </tr>\n","    <tr>\n","      <th>174432</th>\n","      <td>0</td>\n","      <td>not like rock not go</td>\n","    </tr>\n","    <tr>\n","      <th>174433</th>\n","      <td>0</td>\n","      <td>tell friend not lonely deprive are bought litt...</td>\n","    </tr>\n","    <tr>\n","      <th>174434</th>\n","      <td>0</td>\n","      <td>pee probably taste like salty tea drink pee co...</td>\n","    </tr>\n","    <tr>\n","      <th>174435</th>\n","      <td>0</td>\n","      <td>not beat boss hollow knight fight time die ear...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>174436 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["        class                                               text\n","0           1  sex wife threaten suicide recently leave wife ...\n","1           0  weird not affect compliment come know real lif...\n","2           0   finally hear bad year swear fucking god annoying\n","3           1                       need help just help cry hard\n","4           1                       end tonight not anymore quit\n","...       ...                                                ...\n","174431      0  today go sled friend not like of pretty big mi...\n","174432      0                              not like rock not go \n","174433      0  tell friend not lonely deprive are bought litt...\n","174434      0  pee probably taste like salty tea drink pee co...\n","174435      0  not beat boss hollow knight fight time die ear...\n","\n","[174436 rows x 2 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Load dataset and reset index\n","suicide_detection_df = pd.read_csv('Data/suicide_detection_final_cleaned.csv', header=0)\n","suicide_detection_df.reset_index(drop=True, inplace=True)\n","suicide_detection_df.replace({\"class\": {\"suicide\": 1, \"non-suicide\": 0}}, inplace=True)\n","suicide_detection_df.drop(columns=['text'], inplace=True)\n","suicide_detection_df = suicide_detection_df.rename(columns={\"cleaned_text\": \"text\"})\n","suicide_detection_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a3mECsTh9rBR"},"outputs":[],"source":["# Split dataset into train, validation and test sets\n","train_text, test_text, train_labels, test_labels = train_test_split(suicide_detection_df['text'], suicide_detection_df['class'],\n","                                                                    random_state=SEED,\n","                                                                    test_size=0.2,\n","                                                                    stratify=suicide_detection_df['class'])"]},{"cell_type":"markdown","metadata":{"id":"0RUk2ExVLkMf"},"source":["# word2vec"]},{"cell_type":"markdown","metadata":{"id":"rGSa7hfBfnfQ"},"source":["### Building a vocab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1653,"status":"ok","timestamp":1636736699177,"user":{"displayName":"Lim Zi Hui","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPiWA2f_lOpcH4ednxJY0WKKtdAd8lFhippOJxag=s64","userId":"01552686661266028096"},"user_tz":-480},"id":"vPtCt8X_xcky","outputId":"64303444-04a8-4a28-ac69-fcfe4d707f53"},"outputs":[{"name":"stdout","output_type":"stream","text":["20398\n"]}],"source":["# define vocab \n","vocab = Counter()\n","# tokenise each sentence\n","tokens_list = [(s.split()) for s in train_text]\n","# add each sentence to vocab\n","for i in tokens_list:\n","  vocab.update(i)\n","# removing words with a low occurance\n","min_occurance = 2\n","tokens = [k for k,c in vocab.items() if c >= min_occurance]\n","print(len(tokens))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLGQTB_JyoCI"},"outputs":[],"source":["# save list to file\n","def save_list(lines, filename):\n","\t# convert lines to a single blob of text\n","\tdata = '\\n'.join(lines)\n","\t# open file\n","\tfile = open(filename, 'w')\n","\t# write text\n","\tfile.write(data)\n","\t# close file\n","\tfile.close()\n"," \n","# save tokens to a vocabulary file\n","save_list(vocab, 'Data/vocab.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TOnKl1mBvfCi"},"outputs":[],"source":["# load doc into memory\n","def load_doc(filename):\n","\t# open the file as read only\n","\tfile = open(filename, 'r')\n","\t# read all text\n","\ttext = file.read()\n","\t# close the file\n","\tfile.close()\n","\treturn text\n","\n","# load the vocabulary\n","vocab_filename = 'Data/vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = vocab.split()\n","vocab = set(vocab)"]},{"cell_type":"markdown","metadata":{"id":"L0Zaq3_Ef0zf"},"source":["### Removing out-of-vocab words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FVpj2Rvj6_N"},"outputs":[],"source":["# clean each line\n","def clean_line(line, vocab):\n","  tokens = line.split()\n","  # filter out tokens not in vocab\n","  tokens_clean = [w for w in tokens if w in vocab]\n","  return [tokens_clean]\n","\n","# clean entire dataset\n","def process_lines(data, vocab):\n","  lines = list()\n","  for i in data:\n","    line = clean_line(i, vocab)\n","    # add lines to list\n","    lines += line\n","  return lines"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sZRXebQuOEnP"},"outputs":[],"source":["train_clean = process_lines(train_text, vocab)\n","test_clean = process_lines(test_text, vocab)"]},{"cell_type":"markdown","metadata":{"id":"MMVzj2W4XLi1"},"source":["### Training the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45713,"status":"ok","timestamp":1636736831311,"user":{"displayName":"Lim Zi Hui","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPiWA2f_lOpcH4ednxJY0WKKtdAd8lFhippOJxag=s64","userId":"01552686661266028096"},"user_tz":-480},"id":"629baldM_LKc","outputId":"19b00eab-a033-4e70-c7ce-607af862f951"},"outputs":[{"name":"stdout","output_type":"stream","text":["Time to build vocab: 0.15 mins\n","Time to train the model: 0.61 mins\n"]}],"source":["# set up the parameters of the model\n","model = Word2Vec(size=300, window=10, min_count=1, iter=EPOCHS, seed=SEED)\n","\n","# it builds the vocabulary from a sequence of sentences and thus initialized the model.\n","t = time()\n","model.build_vocab(train_clean, progress_per=1000)\n","print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\n","\n","# training the model\n","t = time()\n","model.train(train_clean, total_examples=model.corpus_count, epochs=EPOCHS, report_delay=1)\n","print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Mng2Jq0owLc"},"outputs":[],"source":["# save model in ASCII (word2vec) format\n","filename = 'Data/embedding_word2vec.txt'\n","model.wv.save_word2vec_format(filename, binary=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":353,"status":"ok","timestamp":1636736865646,"user":{"displayName":"Lim Zi Hui","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPiWA2f_lOpcH4ednxJY0WKKtdAd8lFhippOJxag=s64","userId":"01552686661266028096"},"user_tz":-480},"id":"axf16TDur01v","outputId":"7e20fcd7-9d76-4b92-c9ce-730fd29bf6c4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"data":{"text/plain":["[('ethically', 0.7455946207046509),\n"," ('huhheheheuheheuhe', 0.5838792324066162),\n"," ('involuntarily', 0.5762062072753906),\n"," ('suicidal', 0.5316386222839355),\n"," ('unsuccessful', 0.5260963439941406),\n"," ('arson', 0.518305778503418),\n"," ('impulsive', 0.502522349357605),\n"," ('shambles', 0.4928218722343445),\n"," ('suicides', 0.49047738313674927),\n"," ('immolation', 0.4868507385253906)]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model.most_similar('suicide')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
